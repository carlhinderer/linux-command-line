-----------------------------------------------------------
CHAPTER 2 - AUTOMATING FILES AND THE FILESYSTEM
-----------------------------------------------------------

- Reading Files

    # The open() function creates a file object
    >>> file_path = 'bookofdreams.txt'
    >>> open_file = open(file_path, 'r')

    # The read() method returns the file contents as a string
    >>> text = open_file.read()
    >>> len(text)
    >>> 476909
    >>> text[56]
    's'

    >>> open_file
    <_io.TextIOWrapper name='bookofdreams.txt' mode='r' encoding='UTF-8'>

    # It's a good practice to close files manually, although Python will close them automatically
    #   when they are out of scope.
    >>> open_file.close()


    # The readlines() method returns the file contents split on newline characters
    >>> open_file = open(file_path, 'r')
    >>> text = open_file.readlines()
    >>> len(text)
    8796

    >>> text[100]
    'science, when it admits the possibility of occasional hallucinations\n'

    >>> open_file.close()



- Using the with Statement

    # The with statement will cause the file to be closed implicitly
    >>> with open(file_path, 'r') as open_file:
            text = open_file.readlines()



- Opening Binary Files

    # If you open binary files (a jpeg for example) as text, the line ending mismatches
    #   will corrupt the file.  So, we must open it as binary.

    >>> file_path = 'bookofdreamsghos00lang.pdf'
    >>> with open(file_path, 'rb') as open_file:
            btext = open_file.read()

    >>> btext[0]
    37

    >>> btext[:25]
    b'%PDF-1.5\n%\xec\xf5\xf2\xe1\xe4\xef\xe3\xf5\xed\xe5\xee\xf4\n18'



- Writing Files

    # In write mode, the open() function creates a file if it doesn't already exist and 
    #   overwrites it if it does.  To append to a file instead, use the 'a' flag in the mode.

    >>> text = '''export STAGE=PROD
                  export TABLE_ID=token-storage-1234'''

    >>> with open('.envrc', 'w') as opened_file:
            opened_file.write(text)

    >>> !cat .envrc
    export STAGE=PROD
    export TABLE_ID=token-storage-1234



- The pathlib Module

    # The pathlib module has convenience functions for more advanced path handling
    >>> import pathlib
    

    # Read text from a file
    >>> path = pathlib.Path('/Users/joe/test_script.py')
    >>> path.read_text()

    # Write text
    >>> path.write_text('LOG:DEBUG')

    
    # Read binary data
    >>> path = pathlib.Path('/Users/joe/sp.config')
    >>> path.read_bytes()



- Working with JSON

    # Read json file
    >>> import json
    >>> with open('service-policy.json', 'r') as opened_file:
            policy = json.load(opened_file)


    # Pretty-print the json
    >>> from pprint import pprint
    >>> pprint(policy)


    # Use the data from within the file structure
    >>> policy['Statement']['Resource'] = '53'


    # Write a Python dictionary to a JSON file
    >>> with open('service-policy.json' ,'w') as opened_file:
            policy = json.dump(policy, opened_file)



- Working with YAML

    - YAML is a superset of JSON, but has a more compact format, using whitespace similar to how
        Python uses it.  It is used by many tools.

      For instance, Ansible is a tool used to automate software configuration, management, and 
        deployment.  Ansible uses files referred to as playbooks to define actions to automate.


      # PyYAML is the most commonly used library for working with yaml
      $ pip install PyYAML


      # Import data from yaml file
      >>> import yaml
      >>> with open('verfiy-apache.yml', 'r') as opened_file:
              verify_apache = yaml.safe_load(opened_file)


      # Pretty-print data
      >>> pprint(verify_apache)


      # Write to yaml file
      >>> with open('verify-apache.yml', 'w') as opened_file:
              yaml.dump(verify_apache, opened_file)



- Working with XML

    # Read an XML file
    >>> import xml.etree.ElementTree as ET
    >>> tree = ET.parse('http_feeds.feedburner.com_oreilly')


    # Start at the root to traverse the tree
    >>> root = tree.getroot()
    >>> root
    <Element '{http://www.w3.org/2005/Atom}feed' at 0x11292c958>


    # Iterate over the child nodes
    >>> for child in root:
            print(child.tag, child.attrib)


    # Search using XML namespaces
    >>> ns = {'default': 'http://www.w3.org/2005/Atom'}
    >>> authors = root.findall('default:entry/default:author/default:name', ns)

    >>> for author in authors:
            print(author.text)



- Working with CSV

    >>> import csv
    >>> file_path = '/Users/kbehrman/Downloads/registered_user_count_ytd.csv'

    # Read
    >>> with open(file_path, newline='') as csv_file:
            off_reader = csv.reader(csv_file, delimiter=',')
            for _ in range(5):
                print(next(off_reader))

    ['Date', 'PreviousUserCount', 'UserCountTotal', 'UserCountDay']
    ['2014-01-02', '61', '5336', '5275']
    ['2014-01-03', '42', '5378', '5336']
    ['2014-01-04', '26', '5404', '5378']
    ['2014-01-05', '65', '5469', '5404']



- Using pandas DataFrames

    # Read a csv file
    >>> import pandas as pd
    >>> df = pd.read_csv('sample-data.csv') 


    # Look at top rows of file
    >>> df.head(3)


    # Get basic statistics of DataFrame
    >>> df.describe()


    # View a single column
    >>> df['close']



- Using Regular Expressions to Search Text

    - The Apache HTTP server can be configured to save log files in different formats.  One widely used
        format is the 'CLF (Common Log Format)'.  A variety of log analysis tools can be used on this
        format.

      This is the layout of CLF:

        <IP Address> <Client Id> <User Id> <Time> <Request> <Status> <Size>

        # Example
        127.0.0.1 - swills [13/Nov/2019:14:43:30 -0800] "GET /assets/234 HTTP/1.0" 200 2326


    - Now, we'll create some regexes to parse the log entries:

        # Sample log entry
        >>> line = '127.0.0.1 - rj [13/Nov/2019:14:43:30] "GET HTTP/1.0" 200'


        # Get IP address
        >>> re.search(r'(?P<IP>\d+\.\d+\.\d+\.\d+)', line)
        <re.Match object; span=(0, 9), match='127.0.0.1'>

        >>> m = re.search(r'(?P<IP>\d+\.\d+\.\d+\.\d+)', line)
        >>> m.group('IP')
        '127.0.0.1'


        # Get time
        >>> r = r'\[(?P<Time>\d\d/\w{3}/\d{4}:\d{2}:\d{2}:\d{2})\]'
        >>> m = re.search(r, line)
        >>> m.group('Time')
        '13/Nov/2019:14:43:30'


    - We can grab multiple elements, as has been done here:

        # Build regex
        >>> r = r'(?P<IP>\d+\.\d+\.\d+\.\d+)'
        >>> r += r' - (?P<User>\w+) '
        >>> r += r'\[(?P<Time>\d\d/\w{3}/\d{4}:\d{2}:\d{2}:\d{2})\]'
        >>> r += r' (?P<Request>".+")'

        # Search
        >>> m = re.search(r, line)


        # Access matches
        >>> m.group('IP')
        '127.0.0.1'

        >>> m.group('User')
        'rj'

        >>> m.group('Time')
        '13/Nov/2019:14:43:30'

        >>> m.group('Request')
        '"GET HTTP/1.0"'



    - We can use this same regex to pull information out of the entire log, instead of just a single
        line.

        # Build regex
        >>> r = r'(?P<IP>\d+\.\d+\.\d+\.\d+)'
        >>> r += r'- (?P<User>\w+)'
        >>> r += r'\[(?P<Time>08/Nov/\d{4}:\d{2}:\d{2}:\d{2} [-+]\d{4})\]'
        >>> r += r' (?P<Request>"GET .+")'


        # Use finditer to process the log, printing each matching IP address
        >>> matched = re.finditer(r, access_log)
        >>> for m in matched:
                print(m.group('IP'))



- Dealing with Large Files

    - There are times when we need to process very large files.  If the files contain data that can 
        be processed one line at a time, the task is easy with Python.  We can load one line at a time
        into memory, and the lines are removed automatically by the garbage collector.


    - Many common problems arise from the fact that Windows-created files end in '\r\n' while
        Linux-created files end in '\n'.  Python handles the translation for you, so you if you
        want to convert a file, you can open it, read one line at a time, and save it.

        # Convert to your operating system's line endings
        >>> with open('big-data.txt') as source_file:
                with open('big-data-corrected.txt', 'w'):
                    for line in source_file:
                        target_file.write(line)


    - We can define a generator if we need to parse multiple files, a single line at a time.

        # Define a generator to read the file
        >>> def line_reader(file_path):
                with open(file_path, 'r') as source_file:
                    for line in source_file:
                        yield line

        >>> reader = line_reader('big-data.txt')

        # Write to converted file
        >>> with open('big-data-corrected.txt', 'w') as target_file:
                for line in reader:
                    target_file.write(line)


    - If you cannot use line endings as a means of breaking up your data (ie with binary files), you
        can read the data in chunks.

        # Read 1KB at a time
        >>> with open('binarystuff.jpg', 'rb') as source_file:
                while True:
                    chunk = source_file.read(1024)
                    if chunk:
                        process_data(chunk)
                    else:
                        break



- Hashing with hashlib

    - To be secure, user passwords must be stored encrpyted.  A hash function (a one-way function hard
        to reverse) is often used to encrypt a password into a bit string.  Hash functions are also
        commonly used to ensure documents sent over the web were unchanged during transmission.


    - The 'hashlib' library includes several methods for hashing, including:

        SHA1
        SHA224
        SHA384
        SHA512
        MD5


    - Here, we hash a password using the MD5 algorithm:

        # Password is a string
        >>> import hashlib
        >>> secret = 'This is the password'

        # Convert the string into a binary string
        >>> bsecret = secret.encode()

        # Hash the binary string
        >>> m = hashlib.md5()
        >>> m.update(bsecret)

        >>> m.digest()
        b' \xf5\x06\xe6\xfc\x1c\xbe\x86\xddj\x96C\x10\x0f5E'



- The os Module

- Managing Files and Directories Using os.path

- Walking Directory Trees Using os.walk

- Paths as Objects with Pathlib